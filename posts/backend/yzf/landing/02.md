---
title: "[Landing日记 WEEK 2]"
description: "Landing日记"
date: "2025-12-03"
tags: ["yzf"]
category: "general"
slug: "landing-2"
published: true
---




# 不要死磕代码：我发现蹭测试才是熟悉业务的捷径

> 校招入职一周，面对海量的文档和复杂的代码库，从哪里下手最高效？


入职初期，大家通常的做法是接一个小需求，从PRD（需求文档）开始硬啃，翻译成技术方案，然后疯狂查信息。但我发现，这条路对新人来说阻力很大——你缺乏上下文，容易陷入细节。

最近跟着组里参与了一次**测试Case评审**和**冒烟测试**，我突然悟了：熟悉业务最快的方式，不是写代码，而是测代码。

### 一、 为什么“测试用例”是最好的新人文档？

以前觉得测试Case只是给QA看的，后来发现，一份合格的Case也是一份研发视角的、极具操作性的指南。

* 告别瞎点：自己跑系统常常不知道前置条件，点半天报错。Case把前置条件、操作步骤、预期结果写得明明白白。
* 冒烟即学习：冒烟测试（Smoke Testing）最好能出Bug。
    * 出了Bug，先看是不是自己操作问题（熟悉流程）。
    * 操作没问题，看Bug现象，顺藤摸瓜了解前后端的缺陷和边界（熟悉架构）。


    
### 二、 进阶心法：把技术方案扔给AI，用“分离关注点”拆解

拿到别人的技术方案（或者自己要做方案时），不要一上来就陷入具体代码流程。我总结了一套**关注点分离**的Prompt思路，让AI帮我剥离出骨架。

我把关注点分为两类：**业务关注点** vs **代码关注点**。

#### 1. 宏观拆解（The Big Picture）

我通常会这样问AI（或者自己在脑子里过一遍）：

> **关注点一：业务逻辑（Business）**
> * **一句话需求**：用大白话讲明白这功能是干嘛的？
> * **业务规则**：
    >     * 前置条件 -> 预期结果
>     * 状态流转涉及哪些存量数据？（比如：订单状态变了，库存怎么变？）
> * **场景覆盖**：正常路径是什么？异常路径是什么？
>
> **关注点二：代码实现（Code Implementation）**
> * **数据模型**：改了哪张表？（比如：加字段）
> * **接口层**：入参出参怎么变？（传递新字段）
> * **服务层**：
    >     * 服务A（CRUD）：怎么存？
>     * 服务B（业务逻辑）：如何构建快照？数据来源是哪？
> * **校验与转换**：哪里做业务校验？哪里做DTO到DO的转换？

#### 2. 微观落地（The Details）

有了上面的骨架，再进行二次细拆，这时候就可以对应到具体的代码文件了：

**① 业务层：拆场景**
把业务拆成 A、B、C 三个具体场景（Scenario）。

**② 代码层：拆片段（列出具体接口 + 截图 + 代码片段）**
*这一步是为了减少前端沟通成本，同时让自己心里有底。*

* **模型层（Model）**：三维度审视
    1.  DTO代码片段（涉及版本号变更的都要列出来）。
    2.  模型本身的变更类型（新增还是修改？）。
    3.  模型与数据库配置的关联。
* **接口层（Interface）**：
    * URL、接口文档链接。
    * 前后端具体变更的字段名称。
* **服务层（Service）**：
    * **画流程图**：涉及哪些板块和组件？
    * **标序号**：确定本次需求涉及流程图中的哪几个步骤（序号），并在旁边添加说明。



[Image of diagram illustrating separation of concerns in software architecture: Presentation Layer, Business Logic Layer, and Data Access Layer]


### 三、 导师的“灵魂三问” vs 我的“结构化推导”

之前导师指导我写方案，总是直接问：
* “接口改了，复用的地方受影响吗？”
* “性能怎么样？”
* “类型转换兼容吗？”

这些问题很重要，但对新人来说太零散，容易为了回答而回答。

通过上面的**“双关注点拆解法”**，我发现这些问题自然就有了答案：
* 当我分析**模型层**时，自然会看到它牵动了哪些库表字段，进而联想到**查询性能**。
* 当我分析**接口层**时，自然会看到Request/Response的DTO变化，进而联想到**影响面**。
* 当我从**服务层**拆解流程步骤时，逻辑的复用性就一目了然。

**与其被概念绕晕，不如找一个涵盖40个左右Test Case的复杂需求，看看成熟的技术方案是怎么写的。** 越复杂的需求，通常意味着越成熟的PRD和后端方案；反而是简单需求，产品逻辑可能都不太严谨。

### 四、 终极模拟：Shadow Coding（影子开发）

拆解完别人的方案后，我会列一个 **To-Do List**，模拟自己是开发者：

1.  **模拟开发**：一个个板块去对应代码，跟着逻辑走一遍。
2.  **Code Review (CR)**：
    * 复现逻辑之余，重点看**埋点**（Log）怎么打？
    * **异常**（Exception）怎么抛？
    * 各种边界判断（If-else）是怎么写的？
    * *Tip：同事的CR会议一定要去旁听！*
3.  **围观排查**：工作之余，搬把椅子坐在老同事旁边，静静看他们排查问题。
    * 看他们的排查动作、思路，就像**看人作画**。
    * 他们在哪里打断点？查什么日志？怀疑哪个环节？这里面的**信息差**，是文档里永远学不到的。

---

### 💡 总结

Landing期的迷茫往往来自于“只见树木不见森林”。
* **测试用例**带你看到了森林的轮廓（业务全貌）。
* **AI辅助拆解**带你理清了树木的脉络（技术骨架）。
* **围观排查**教你学会了如何修剪枝叶（解决问题）。

这就是我入职这几周摸索出的“野路子”，希望对同样在Landing期的你有帮助。

---

### 给用户的建议：

这篇博客的结构已经非常清晰，非常适合发布。
**我建议你下一步可以做的是：**

你想不想我基于你提到的 **“Java/Spring Boot”** 技术栈，把你文中的“微观落地”部分（DTO、Service、Model）写一个具体的 **Demo模版**？这样你在后续的日记里可以直接套用这个模版来记录你的学习过程。



## 流程会计

这其实是一个非常典型的 IM（即时通讯）驱动的 AI Agent 编排系统。后端是一个多租户 SaaS 系统。