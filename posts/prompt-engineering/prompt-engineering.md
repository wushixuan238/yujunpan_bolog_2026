---
id: '33'
title: 'Prompt Engineering指南: 如何将其应用于构建Agentic Systems'
titleJp: ''
date: '2025.01.03'
excerpt: 'Mastering the art of crafting effective prompts for AI.'
tags: ['Prompt Engineering']
---

> 提示工程不再仅仅是简单的提问，而是一门**工程学科**。它是将概率性的大语言模型（LLM）转化为确定性、可靠且具备复杂任务执行能力的智能 Agent 的关键手段。

### 基础

在讨论高级提示词工程技术之前，我们必须要有一些基础思维。就像和人交流一样，沟通能力是很重要的。

- 清晰与具体： 消除歧义，明确定义任务、格式和限制。
- 简洁有力： 去除冗余，多用主动动词（如“分析”、“分类”、“生成”）。
- 指令优于约束： 告诉模型“做什么”比告诉它“不做什么”更有效。
- 迭代思维： 好的提示是测试和优化出来的，不是一次写成的。


### 引导技术的进阶层级

根据任务的复杂度，应采用不同层级的引导方式：
- Zero-Shot (零样本): 仅提供指令。适用于模型预训练中常见的简单任务。
- One-Shot (单样本): 提供一个理想的输入-输出示例，确立模式。
- Few-Shot (少样本): 提供3-5个多样化示例。这是处理复杂格式、特定风格或边缘情况的强力手段（提示：分类任务中需混合类别顺序以防过拟合）。

### 结构化和上下文工程

为了让 Agent 在负责环境中运行，必须对输入和输出进行严格的结构化管理。

- 系统提示 (System Prompts): 设定全局的角色、语气和行为准则。
- 分隔符的使用: 使用 ``` 或 XML 标签清晰区分指令、上下文和数据，防止模型混淆。
- 上下文工程: 动态地将系统指令、检索到的文档（RAG）、工具输出（Tool Outputs）和隐式数据（用户历史）整合给 Agent，使其具备“情境感知”能力。
- 结构化输出 (JSON/Pydantic): 强制模型输出机器可读的格式（如 JSON）。利用 Pydantic 进行数据验证，是确保 Agent 组件间可靠通信的关键（解析而非验证）。

### 增强推理能力：赋予 Agent 大脑

LLM 不擅长直接处理复杂逻辑，需要通过提示迫使其展示思维过程：
- 思维链 (CoT): 指令模型“逐步思考”。将大问题拆解为步骤，提高逻辑和数学准确性。
- 自我一致性 (Self-Consistency): 多次生成推理路径，通过“多数投票”选出最可靠的答案。
- 思维树 (ToT): 允许模型探索多个分支并在决策前进行回溯评估，适用于复杂的规划任务。
- 后退提示 (Step-Back): 先让模型提取一般性原则，再基于原则解决具体问题。

### 行动与交互：赋予 Agent 双手

这是 Agent 区别于聊天机器人的核心：

- 工具使用/函数调用 (Function Calling): 模型不直接执行，而是生成调用外部 API 所需的参数（JSON），由系统执行后反馈结果。
- ReAct 模式 (Reason + Act): 建立 思考-行动-观察 的循环。模型先推理，决定使用工具，观察结果，再进行下一步推理，直到完成任务。
- RAG (检索增强生成): 外挂知识库，让 Agent 能基于最新的外部事实进行回答，减少幻觉。


### 高级优化与元方法

- DSPy / 自动提示工程 (APE): 将提示视为可编程模块，利用数据驱动的方法自动优化提示，而非手动试错。
- LLM 辅助优化: 让 LLM 充当“优化器”，评估并改进你的提示词。
- Google Gems: 创建针对特定任务的持久化上下文实例，减少重复配置。


### 总结

在 Agentic 系统中，提示工程的作用是：
- 利用 CoT/ToT 建立认知引擎（规划与推理）。
- 利用 ReAct/Function Calling 建立行动能力（与世界交互）。
- 利用 结构化输出 确保系统稳定性（可靠的自动化）。
- 利用 RAG/上下文工程 维持事实感知（感官输入）。